# -*- coding: utf-8 -*-
import re
import time
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime

@dataclass
class AnalysisResult:
    """æƒ…æ„Ÿåˆ†æç»“æœ"""
    tag: Optional[str]
    score: float
    priority: int
    confidence: float
    details: Dict[str, any]
    mixed_emotions: List[Tuple[str, float]]

@dataclass
class FeedbackRecord:
    """ç”¨æˆ·åé¦ˆè®°å½•"""
    text: str
    predicted_tag: str
    correct_tag: Optional[str]
    timestamp: float
    user_id: Optional[str] = None
    confidence: float = 0.0

@dataclass
class UserPreferences:
    """ç”¨æˆ·åå¥½"""
    user_id: str
    emotion_weights: Dict[str, float] = field(default_factory=dict)
    common_phrases: Dict[str, str] = field(default_factory=dict)
    last_active: float = 0.0
    total_interactions: int = 0

class SentimentAnalyzer:
    
    def __init__(self, data_dir: Optional[Path] = None):
        self._compile_patterns()
        self._init_data()
        self._init_advanced_features()
        self._init_learning_system(data_dir)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_analyzed": 0,
            "cache_hits": 0,
            "avg_time": 0.0,
            "feedback_count": 0,
            "learning_updates": 0
        }

    def _compile_patterns(self):
        self.re_repeat_chars = re.compile(r"(.)\1{2,}")
        self.re_question = re.compile(r"(ä½ |æ‚¨|ç‰¹|çš‡|æ®¿).*[?ï¼Ÿå—]")
        self.re_negation_scope = re.compile(r"(ä¸|æ²¡|åˆ«|å‹¿|æ— |é|å‡|è«|æœª|å¦|ç¦æ­¢)[^\sï¼Œã€‚ï¼ï¼Ÿ]{0,10}")
        self.re_conjunction = re.compile(r"(ä½†æ˜¯|å¯æ˜¯|ç„¶è€Œ|ä¸è¿‡|è™½ç„¶|å°½ç®¡)")

    def _init_advanced_features(self):
        self.ADVANCED_CONFIG = {
            "enable_position_weight": True,
            "enable_context_aware": True,
            "enable_mixed_emotion": True,
            "enable_text_length_norm": True,
            "enable_word_order": True,
            "enable_learning": True,
            "enable_personalization": True,
            "position_decay": 0.8,
            "text_length_factor": 0.1,
            "conjunction_penalty": 0.5,
            "negation_scope": 8,
            "learning_rate": 0.1,
            "feedback_threshold": 5,
            "max_weight_adjustment": 2.0
        }

    def _init_learning_system(self, data_dir: Optional[Path] = None):
        """åˆå§‹åŒ–å­¦ä¹ ç³»ç»Ÿ"""
        if data_dir is None:
            data_dir = Path(__file__).parent / "data"
        
        self.data_dir = data_dir
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.feedback_file = self.data_dir / "feedback.json"
        self.preferences_file = self.data_dir / "user_preferences.json"
        
        # åé¦ˆè®°å½•
        self.feedback_records: List[FeedbackRecord] = []
        self._load_feedback()
        
        # ç”¨æˆ·åå¥½
        self.user_preferences: Dict[str, UserPreferences] = {}
        self._load_user_preferences()

    def _init_data(self):
        self.EMOTION_NODES = {
            "morning": {
                "keywords": [
                    "æ—©å®‰", "æ—©ä¸Šå¥½", "æ—©å•Š", "å“¦å“ˆå“Ÿ", "æ—©", "å¯åŠ¨", "é†’äº†", 
                    "èµ·é£", "morning", "hi", "å“ˆå–½", "ä½ å¥½", "æ‚¨å¥½", "æ—©ä¸Š", 
                    "åˆšé†’", "å›°æ­»", "ççœ¼", "æç¥", "å’–å•¡", "æ‰“å¡"
                ],
                "regex": [r"æ—©$", r"æ—©.*å¥½", r"^æ—©", r"morning"],
                "emojis": ["ğŸŒ…", "â˜•", "ğŸ”", "â˜€ï¸", "ğŸ‘‹", "ğŸ¥ª", "ğŸ¥›"],
                "base_score": 6.0,
                "priority": 0,
                "position_bonus": 1.2,
                "category": "greeting"
            },

            "sanity": {
                "keywords": [
                    "æ™šå®‰", "ç¡äº†", "ç¡è§‰", "ç´¯", "ä¼‘æ¯", "å›°", "ä¼‘çœ ", "ä¸‹ç­", 
                    "åˆç¡", "èººå¹³", "æ­‡ä¼š", "ä¹", "å€¦", "æŒ‚æœº",
                    "ç†æ™º", "ç¢çŸ³", "åƒçŸ³å¤´", "æ“ç‰", "è‚", "1-7", "åˆ·ææ–™", 
                    "é•¿è‰", "åŸºå»º", "æ’ç­", "æ¢ç­", "æ¸…ç†æ™º", "å‰¿ç­", "ä»£ç†",
                    "åŠ ç­", "çŒæ­»", "é€šå®µ", "ç†¬å¤œ", "åšé¢˜", "èµ¶ddl", "å¼€ä¼š",
                    "æ‘¸é±¼", "ä¸æƒ³åŠ¨", "ç˜«", "ç´¯æ­»"
                ],
                "regex": [
                    r"(å»|è¦|æƒ³)ç¡", r"å¥½{0,2}ç´¯", r"å›°.*æ­»", r"çœ¼.*çä¸å¼€", 
                    r"è‚.*ç–¼", r"ç†.*æ™º.*(æ— |æ²¡|å…‰|0)", r"ä¸‹.*ç­", r"æ™š.*å®‰"
                ],
                "emojis": ["ğŸ’¤", "ğŸŒ™", "ğŸ›Œ", "ğŸ¥±", "ğŸ˜ª", "ğŸŒƒ", "ğŸ”‹", "ğŸª«"],
                "base_score": 6.0,
                "priority": 0,
                "position_bonus": 1.0,
                "category": "fatigue"
            },

            "dont_cry": {
                "keywords": [
                    "ç—›è‹¦", "æƒ³å“­", "éš¾å—", "ä¼¤å¿ƒ", "æ‚²ä¼¤", "æµæ³ª", "å“­",
                    "ç ´é˜²", "å´©æºƒ", "ç”šè‡³æƒ³ç¬‘", "emo", "å‘œ", "ç‰ç‰", "åœ°ç‹±", 
                    "å¯„", "ä¼¼äº†", "è£‚å¼€", "éº»äº†", "å°ä¸‘", "çº¢æ¸©", "å¿ƒæ€å´©",
                    "è‡´éƒ", "åˆ€", "å‘ç—…", "é—æ†¾", "å”‰", "å¹æ°”"
                ],
                "regex": [
                    r"å¥½{0,2}(ç—›|è‹¦)", r"å‘œ{3,}", r"ä¸æƒ³.*æ´»", r"å¿ƒ.*æ€.*å´©", 
                    r"ç ´.*å¤§.*é˜²", r"æ•‘.*æˆ‘", r"ç¬‘.*ä¸.*å‡º.*æ¥"
                ],
                "emojis": ["ğŸ˜­", "ğŸ˜¢", "ğŸ’”", "ğŸ¥€", "ğŸ’§", "ğŸŒ§ï¸", "ğŸ˜¿", "ğŸ˜", "ğŸ©¸"],
                "base_score": 7.5,
                "priority": 1,
                "position_bonus": 1.3,
                "category": "sadness"
            },

            "comfort": {
                "keywords": [
                    "æ•‘å‘½", "å®³æ€•", "ææ€–", "å“äºº", "å§”å±ˆ", "æ€•", "é˜´é—´", 
                    "å™©æ¢¦", "é¬¼", "ç„¦è™‘", "ç´§å¼ ", "å‹åŠ›", "çª’æ¯", "æ…Œ", 
                    "help", "sos", "ä¸æ•¢", "å‘æŠ–", "å“æ­»"
                ],
                "regex": [
                    r"è¢«.*å“", r"å¥½{0,2}æ€•", r"æ•‘.*å‘½", r"å“.*æ­»", 
                    r"åˆ«.*å“.*æˆ‘", r"å¸®.*å¸®.*æˆ‘"
                ],
                "emojis": ["ğŸ˜±", "ğŸ˜¨", "ğŸ˜–", "ğŸ†˜", "ğŸ‘»", "ğŸ§Ÿ", "ğŸ•·ï¸", "ğŸ˜°"],
                "base_score": 8.0,
                "priority": 2,
                "position_bonus": 1.5,
                "category": "fear"
            },

            "fail": {
                "keywords": [
                    "å¤±è´¥", "è¾“äº†", "ç™½ç»™", "å¦‚æœ", "å‡å¦‚", "åæ‚”", "èœ", "å¼±",
                    "æ²‰èˆ¹", "ä¿åº•", "è“å¤©ç™½äº‘", "ç´«æ°”ä¸œæ¥", "æ½œèƒ½", "æ­ªäº†", 
                    "æ¼æ€ª", "ä»£ç†å¤±è¯¯", "æ¼”æˆ‘", "ä¸è¡€", "ç¿»è½¦", "æ‰‹æ®‹", 
                    "è„‘æº¢è¡€", "è¡€å‹", "ä¸‹é¥­", "æ“ä½œå˜å½¢", "æ‰“ä¸è¿‡", "å¡å…³"
                ],
                "regex": [
                    r"æ‰“.*ä¸è¿‡", r"è¿‡.*ä¸å»", r"è¾“.*äº†", r"é«˜.*è¡€.*å‹", 
                    r"æŠ½.*ä¸.*åˆ°", r"æ­ª.*äº†"
                ],
                "emojis": ["ğŸ³ï¸", "ğŸ’€", "ğŸ‘", "ğŸ¤¡", "ğŸ“‰", "ğŸ’©"],
                "base_score": 6.0,
                "priority": 0,
                "position_bonus": 1.1,
                "category": "failure"
            },

            "company": {
                "keywords": [
                    "å­¤ç‹¬", "å¯‚å¯", "æ²¡äºº", "ä¸€ä¸ªäºº", "æ— èŠ", "å†·æ¸…", "ç†æˆ‘", 
                    "è‡ªé—­", "å­¤å•", "è½å¯", "ç©ºè™š", "æ²¡äººçˆ±", "å­¤å¯¡", 
                    "åªæœ‰ä½ ", "é™ªæˆ‘", "èŠèŠ", "è¯´è¯"
                ],
                "regex": [
                    r"ç†.*æˆ‘", r"åœ¨.*å—", r"æ²¡.*äºº", r"ä¸€.*ä¸ª.*äºº", r"é™ª.*é™ª.*æˆ‘"
                ],
                "emojis": ["ğŸƒ", "ğŸ‚", "ğŸª¹", "ğŸ˜¶", "ğŸŒ«ï¸", "ğŸš¶"],
                "base_score": 5.0,
                "priority": 0,
                "position_bonus": 1.0,
                "category": "loneliness"
            },

            "trust": {
                "keywords": [
                    "è€å©†", "ç‰¹é›·è¥¿å¨…", "æ®¿ä¸‹", "çš‡å¥³", "ç‰¹è•¾è¥¿å¨…", "å¥³ç‹",
                    "æŠ±æŠ±", "è´´è´´", "å–œæ¬¢", "çˆ±", "å¤ªå¼º", "å‰å®³", "æƒ³ä½ ", 
                    "äº²äº²", "ç»“å©š", "æˆ’æŒ‡", "ç¾ç»Š", "æƒ³å¿µ", "å¿ƒåŠ¨", "å¯çˆ±",
                    "æ¸©æŸ”", "å¤©ä½¿", "å¦ˆå¦ˆ", "æˆ‘çˆ±ä½ ", "love"
                ],
                "regex": [
                    r"æœ€.*å–œæ¬¢", r"çˆ±.*ä½ ", r"æƒ³.*ä½ ", r"ç»“.*å©š", r"è€.*å©†", 
                    r"è´´.*è´´", r"æŠ±.*æŠ±"
                ],
                "emojis": ["â¤ï¸", "ğŸ¥°", "ğŸ¤—", "ğŸ˜˜", "ğŸ’", "ğŸŒ¹", "âœ¨", "ğŸ˜»", "ğŸ’•"],
                "base_score": 5.0,
                "priority": 0,
                "position_bonus": 1.2,
                "category": "affection"
            },

            "poke": {
                "keywords": [
                    "æˆ³", "æ‰", "æ‘¸", "æ£", "rua", "æ", "æ•²", "æ‹", 
                    "æ‘¸æ‘¸", "æ‘¸å¤´", "æŠŠç©", "æŒ‡æŒ‡ç‚¹ç‚¹"
                ],
                "regex": [r"æˆ³.*æˆ³", r"æ‘¸.*æ‘¸"],
                "emojis": ["ğŸ‘ˆ", "ğŸ‘†", "ğŸ¤", "ğŸ‘‹"],
                "base_score": 4.0,
                "priority": 0,
                "position_bonus": 1.0,
                "category": "interaction"
            },

            "anger": {
                "keywords": [
                    "ç”Ÿæ°”", "æ„¤æ€’", "ç«å¤§", "çƒ¦", "çƒ¦æ­»äº†", "æ»š", "æ»šè›‹",
                    "è®¨åŒ", "æ¶å¿ƒ", "æ¶å¿ƒ", "æš´èº", "ç‚¸äº†", "æ°”æ­»",
                    "æ— è¯­", "æ— è¯­", "é ", "æ“", "tmd", "tm", "cnm",
                    "æ„¤æ€’", "æ€’", "æ¼ç«", "ä¸çˆ½", "ä¸çˆ½"
                ],
                "regex": [
                    r"å¥½{0,2}(çƒ¦|æ°”|æ€’)", r"çƒ¦.*æ­»", r"æ°”.*æ­»", r"ç‚¸.*äº†",
                    r"æ»š.*è›‹", r"æ— .*è¯­", r"ä¸.*çˆ½"
                ],
                "emojis": ["ğŸ˜¡", "ğŸ˜¤", "ğŸ¤¬", "ğŸ’¢", "ğŸ’¥", "ğŸ”¥", "ğŸ‘Š"],
                "base_score": 7.0,
                "priority": 1,
                "position_bonus": 1.3,
                "category": "anger"
            },

            "surprise": {
                "keywords": [
                    "å“‡", "å¤©å“ª", "å¤©å•Š", "éœ‡æƒŠ", "æƒŠè®¶", "æ„å¤–", "æ²¡æƒ³åˆ°",
                    "çœŸçš„å—", "ä¸ä¼šå§", "å±…ç„¶", "ç«Ÿç„¶", "éš¾ä»¥ç½®ä¿¡",
                    "wow", "omg", "å¤©", "å•Š", "è¯¶", "å’¦"
                ],
                "regex": [
                    r"å“‡{2,}", r"å¤©.*å“ª", r"å¤©.*å•Š", r"éœ‡.*æƒŠ",
                    r"æ„.*å¤–", r"æ²¡.*æƒ³.*åˆ°", r"å±…ç„¶", r"ç«Ÿç„¶"
                ],
                "emojis": ["ğŸ˜²", "ğŸ˜®", "ğŸ˜¯", "ğŸ¤¯", "ğŸ˜±", "ğŸ˜³", "ğŸ™€"],
                "base_score": 5.5,
                "priority": 0,
                "position_bonus": 1.1,
                "category": "surprise"
            },

            "hope": {
                "keywords": [
                    "æœŸå¾…", "åŠ æ²¹", "ç›¸ä¿¡", "å¸Œæœ›", "åŠªåŠ›", "åšæŒ", "å¥‹æ–—",
                    "ä¸€å®š", "è‚¯å®š", "ä¼šå¥½çš„", "æ²¡é—®é¢˜", "èƒ½è¡Œ", "å¯ä»¥",
                    "æœªæ¥", "æ˜å¤©", "æ¢¦æƒ³", "ç›®æ ‡", "ç†æƒ³", "æ„¿æœ›"
                ],
                "regex": [
                    r"åŠ .*æ²¹", r"ç›¸.*ä¿¡", r"å¸Œ.*æœ›", r"ä¸€.*å®š",
                    r"è‚¯.*å®š", r"æ²¡.*é—®.*é¢˜", r"èƒ½.*è¡Œ"
                ],
                "emojis": ["ğŸ’ª", "ğŸŒŸ", "âœ¨", "ğŸŒˆ", "ğŸ¯", "ğŸš€", "ğŸ’«"],
                "base_score": 5.5,
                "priority": 0,
                "position_bonus": 1.1,
                "category": "hope"
            },

            "gratitude": {
                "keywords": [
                    "è°¢è°¢", "æ„Ÿè°¢", "è¾›è‹¦äº†", "å¤šè°¢", "æ„Ÿè°¢", "è°¢å•¦",
                    "thank", "thanks", "æ„Ÿæ¿€", "æ‹œæ‰˜", "éº»çƒ¦", "ä¸å¥½æ„æ€"
                ],
                "regex": [
                    r"è°¢.*è°¢", r"æ„Ÿ.*è°¢", r"è¾›.*è‹¦", r"å¤š.*è°¢",
                    r"æ‹œ.*æ‰˜", r"éº».*çƒ¦"
                ],
                "emojis": ["ğŸ™", "ğŸ™Œ", "ğŸ’", "ğŸ", "â¤ï¸", "ğŸ¤"],
                "base_score": 5.0,
                "priority": 0,
                "position_bonus": 1.0,
                "category": "gratitude"
            },

            "confusion": {
                "keywords": [
                    "ä¸æ‡‚", "ä¸ç†è§£", "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆå›äº‹", "å•¥", "ä»€ä¹ˆ",
                    "æä¸æ‡‚", "ä¸çŸ¥é“", "ä¸æ˜ç™½", "ç–‘é—®", "ç–‘æƒ‘", "å›°æƒ‘",
                    "how", "why", "what", "æ€ä¹ˆ", "å¦‚ä½•"
                ],
                "regex": [
                    r"ä¸.*æ‡‚", r"ä¸.*ç†.*è§£", r"ä¸º.*ä»€.*ä¹ˆ", r"æ€.*ä¹ˆ.*å›.*äº‹",
                    r"æ.*ä¸.*æ‡‚", r"ä¸.*æ˜.*ç™½"
                ],
                "emojis": ["ğŸ¤”", "â“", "â“", "ğŸ¤·", "ğŸ¤·â€â™‚ï¸", "ğŸ¤·â€â™€ï¸"],
                "base_score": 4.5,
                "priority": 0,
                "position_bonus": 1.0,
                "category": "confusion"
            },

            "excitement": {
                "keywords": [
                    "å¤ªæ£’äº†", "æ¿€åŠ¨", "å¼€å¿ƒ", "å¿«ä¹", "å…´å¥‹", "çˆ½", "çˆ½äº†",
                    "å‰å®³", "ç‰›", "ç‰›é€¼", "666", "å¼º", "å¼ºå•Š", "å¤ªå¼ºäº†",
                    "happy", "joy", "å¤ªå¥½äº†", "å¤ªå¼€å¿ƒäº†", "å¤ªçˆ½äº†"
                ],
                "regex": [
                    r"å¤ª.*æ£’", r"æ¿€.*åŠ¨", r"å¼€.*å¿ƒ", r"å¿«.*ä¹",
                    r"çˆ½.*äº†", r"ç‰›.*é€¼", r"666", r"å¤ª.*å¥½", r"å¤ª.*å¼º"
                ],
                "emojis": ["ğŸ‰", "ğŸŠ", "ğŸ¥³", "ğŸ˜„", "ğŸ˜", "ğŸ¤©", "âœ¨", "ğŸŒŸ"],
                "base_score": 6.5,
                "priority": 0,
                "position_bonus": 1.2,
                "category": "excitement"
            },

            "disappointment": {
                "keywords": [
                    "å¤±æœ›", "æ²¡æ„æ€", "æ— èŠ", "æ²¡åŠ²", "æ²¡è¶£", "æ²¡æ„æ€",
                    "ç®—äº†", "ç®—äº†ç®—äº†", "æ— æ‰€è°“", "ä¸åœ¨ä¹", "éšä¾¿", "éšä¾¿å§",
                    "æ²¡åŠ²", "æ²¡æ„æ€", "æ²¡è¶£", "æ²¡æ„æ€"
                ],
                "regex": [
                    r"å¤±.*æœ›", r"æ²¡.*æ„.*æ€", r"æ— .*èŠ", r"æ²¡.*åŠ²",
                    r"ç®—.*äº†", r"æ— .*æ‰€.*è°“", r"éš.*ä¾¿"
                ],
                "emojis": ["ğŸ˜‘", "ğŸ˜’", "ğŸ™„", "ğŸ˜", "ğŸ˜”", "ğŸ’”"],
                "base_score": 4.5,
                "priority": 0,
                "position_bonus": 1.0,
                "category": "disappointment"
            },

            "pride": {
                "keywords": [
                    "éª„å‚²", "è‡ªè±ª", "å‰å®³", "ç‰›", "ç‰›é€¼", "å¼º", "å¼ºå•Š",
                    "å¤ªå¼ºäº†", "å¤ªå‰å®³äº†", "å¤ªç‰›äº†", "å¤ªç‰›é€¼äº†", "å¤ªéª„å‚²äº†",
                    "awesome", "great", "amazing", "excellent"
                ],
                "regex": [
                    r"éª„.*å‚²", r"è‡ª.*è±ª", r"å‰.*å®³", r"ç‰›.*é€¼",
                    r"å¤ª.*å¼º", r"å¤ª.*ç‰›", r"å¤ª.*å‰.*å®³"
                ],
                "emojis": ["ğŸ†", "ğŸ¥‡", "ğŸŒŸ", "âœ¨", "ğŸ’ª", "ğŸ–ï¸"],
                "base_score": 6.0,
                "priority": 0,
                "position_bonus": 1.2,
                "category": "pride"
            }
        }

        self.MODIFIERS = {
            "super": {
                "words": [
                    "å¥½", "å¤ª", "çœŸ", "éå¸¸", "è¶…çº§", "æ­»", "ç‰¹åˆ«", "å·¨", "æå…¶", 
                    "è¶…", "çˆ†", "ç»", "é¡¶çº§", "å‰§çƒˆ", "ç©¶æ", "å®Œå…¨", "å½»åº•"
                ], 
                "weight": 1.5,
                "priority": 3
            },
            "mid": {
                "words": ["æ¯”è¾ƒ", "è¿˜", "æŒº", "è›®", "ç›¸å½“"], 
                "weight": 1.2,
                "priority": 2
            },
            "little": {
                "words": ["ä¸€ç‚¹", "æœ‰ç‚¹", "æœ‰äº›", "ä¼¼", "å¾®", "ç¨"], 
                "weight": 0.8,
                "priority": 1
            },
            "negate": {
                "words": [
                    "ä¸", "æ²¡", "åˆ«", "å‹¿", "æ— ", "é", "å‡", "è«", 
                    "æœª", "å¦", "ç¦æ­¢"
                ], 
                "weight": -1.0,
                "priority": 10
            }
        }
        
        self.WINDOW_SIZE = 6

    def analyze(self, text: str, user_id: Optional[str] = None, enable_negation: bool = True) -> Tuple[Optional[str], float]:
        start_time = time.time()
        self.stats["total_analyzed"] += 1
        
        result = self._analyze_advanced(text, user_id, enable_negation)
        
        elapsed = time.time() - start_time
        self.stats["avg_time"] = (
            self.stats["avg_time"] * (self.stats["total_analyzed"] - 1) + elapsed
        ) / self.stats["total_analyzed"]
        
        return result.tag, result.score

    def _analyze_advanced(self, text: str, user_id: Optional[str], enable_negation: bool) -> AnalysisResult:
        text_lower = text.lower()
        text_len = len(text)
        
        final_scores = {tag: 0.0 for tag in self.EMOTION_NODES}
        max_priorities = {tag: 0 for tag in self.EMOTION_NODES}
        match_details = defaultdict(list)
        
        global_boost = self._calculate_global_boost(text)
        question_penalty = self._calculate_question_penalty(text)
        text_norm_factor = self._calculate_text_length_norm(text_len)
        
        # åº”ç”¨ç”¨æˆ·ä¸ªæ€§åŒ–æƒé‡
        user_weight_multiplier = self._get_user_weight_multiplier(user_id, text)
        
        for tag, data in self.EMOTION_NODES.items():
            base = data['base_score']
            priority = data['priority']
            position_bonus = data.get('position_bonus', 1.0)
            
            tag_matches = []
            
            for kw in data['keywords']:
                if kw in text_lower:
                    for match in re.finditer(re.escape(kw), text_lower):
                        pos_weight = self._calculate_position_weight(
                            match.start(), text_len, position_bonus
                        )
                        
                        score = self._calculate_node_weight(
                            text_lower, match.start(), match.end(), base, pos_weight
                        )
                        
                        # åº”ç”¨ç”¨æˆ·ä¸ªæ€§åŒ–æƒé‡
                        score *= user_weight_multiplier.get(tag, 1.0)
                        
                        final_scores[tag] += score
                        max_priorities[tag] = max(max_priorities[tag], priority)
                        
                        tag_matches.append({
                            "type": "keyword",
                            "text": kw,
                            "pos": match.start(),
                            "score": score
                        })
            
            for pattern in data['regex']:
                for match in re.finditer(pattern, text_lower):
                    pos_weight = self._calculate_position_weight(
                        match.start(), text_len, position_bonus
                    )
                    
                    score = self._calculate_node_weight(
                        text_lower, match.start(), match.end(), base + 2.0, pos_weight
                    )
                    
                    score *= user_weight_multiplier.get(tag, 1.0)
                    
                    final_scores[tag] += score
                    max_priorities[tag] = max(max_priorities[tag], priority)
                    
                    tag_matches.append({
                        "type": "regex",
                        "text": match.group(),
                        "pos": match.start(),
                        "score": score
                    })
            
            for emoji in data['emojis']:
                if emoji in text:
                    count = text.count(emoji)
                    score = 1.5 * count
                    score *= user_weight_multiplier.get(tag, 1.0)
                    final_scores[tag] += score
                    
                    tag_matches.append({
                        "type": "emoji",
                        "text": emoji,
                        "pos": text.find(emoji),
                        "score": score
                    })
            
            match_details[tag] = tag_matches
        
        candidates = {}
        for k, v in final_scores.items():
            final_v = v * global_boost * question_penalty * text_norm_factor
            if final_v > 0:
                candidates[k] = final_v
        
        if not candidates:
            return AnalysisResult(None, 0, 0, 0, {}, [])
        
        sorted_candidates = sorted(
            [(k, v, max_priorities[k]) for k, v in candidates.items()],
            key=lambda item: (item[2], item[1]),
            reverse=True
        )
        
        best_tag, best_score, best_priority = sorted_candidates[0]
        
        threshold = 2.5 if best_priority > 0 else 3.5
        
        if best_score < threshold:
            return AnalysisResult(None, 0, 0, 0, {}, [])
        
        confidence = self._calculate_confidence(best_score, threshold, best_priority)
        
        mixed_emotions = []
        if self.ADVANCED_CONFIG["enable_mixed_emotion"]:
            mixed_emotions = self._detect_mixed_emotions(
                [(k, v) for k, v in candidates.items() if v > threshold * 0.7]
            )
        
        return AnalysisResult(
            tag=best_tag,
            score=best_score,
            priority=best_priority,
            confidence=confidence,
            details={
                "matches": match_details[best_tag],
                "global_boost": global_boost,
                "question_penalty": question_penalty,
                "text_norm_factor": text_norm_factor,
                "user_weight_multiplier": user_weight_multiplier
            },
            mixed_emotions=mixed_emotions
        )

    def _get_user_weight_multiplier(self, user_id: Optional[str], text: str) -> Dict[str, float]:
        """è·å–ç”¨æˆ·ä¸ªæ€§åŒ–æƒé‡ä¹˜æ•°"""
        if not user_id or not self.ADVANCED_CONFIG["enable_personalization"]:
            return {}
        
        if user_id not in self.user_preferences:
            return {}
        
        prefs = self.user_preferences[user_id]
        multiplier = {}
        
        for tag, weight in prefs.emotion_weights.items():
            if weight != 1.0:
                multiplier[tag] = weight
        
        return multiplier

    def record_feedback(self, text: str, predicted_tag: str, correct_tag: Optional[str], user_id: Optional[str] = None):
        """è®°å½•ç”¨æˆ·åé¦ˆ"""
        record = FeedbackRecord(
            text=text,
            predicted_tag=predicted_tag,
            correct_tag=correct_tag,
            timestamp=time.time(),
            user_id=user_id
        )
        
        self.feedback_records.append(record)
        self.stats["feedback_count"] += 1
        
        # è§¦å‘å­¦ä¹ æ›´æ–°
        if len(self.feedback_records) >= self.ADVANCED_CONFIG["feedback_threshold"]:
            self._update_weights_from_feedback()
        
        # æ›´æ–°ç”¨æˆ·åå¥½
        if user_id and correct_tag:
            self._update_user_preferences(user_id, text, correct_tag)
        
        # ä¿å­˜åé¦ˆ
        self._save_feedback()

    def _update_weights_from_feedback(self):
        """æ ¹æ®åé¦ˆæ›´æ–°æƒé‡"""
        if not self.ADVANCED_CONFIG["enable_learning"]:
            return
        
        learning_rate = self.ADVANCED_CONFIG["learning_rate"]
        max_adjustment = self.ADVANCED_CONFIG["max_weight_adjustment"]
        
        # ç»Ÿè®¡æ¯ä¸ªæ ‡ç­¾çš„åé¦ˆ
        feedback_stats = defaultdict(lambda: {"correct": 0, "wrong": 0})
        
        for record in self.feedback_records[-100:]:  # åªç”¨æœ€è¿‘100æ¡
            if record.correct_tag:
                if record.predicted_tag == record.correct_tag:
                    feedback_stats[record.correct_tag]["correct"] += 1
                else:
                    feedback_stats[record.predicted_tag]["wrong"] += 1
        
        # æ›´æ–°åŸºç¡€åˆ†æ•°
        for tag, stats in feedback_stats.items():
            if tag not in self.EMOTION_NODES:
                continue
            
            total = stats["correct"] + stats["wrong"]
            if total == 0:
                continue
            
            accuracy = stats["correct"] / total
            
            # å‡†ç¡®ç‡é«˜åˆ™å¢åŠ æƒé‡ï¼Œå‡†ç¡®ç‡ä½åˆ™é™ä½æƒé‡
            adjustment = (accuracy - 0.5) * 2 * learning_rate
            adjustment = max(min(adjustment, max_adjustment), -max_adjustment)
            
            self.EMOTION_NODES[tag]["base_score"] = max(
                self.EMOTION_NODES[tag]["base_score"] * (1 + adjustment),
                1.0  # æœ€å°å€¼ä¸º1.0
            )
        
        self.stats["learning_updates"] += 1
        self._save_emotion_nodes()

    def _update_user_preferences(self, user_id: str, text: str, correct_tag: str):
        """æ›´æ–°ç”¨æˆ·åå¥½"""
        if user_id not in self.user_preferences:
            self.user_preferences[user_id] = UserPreferences(user_id=user_id)
        
        prefs = self.user_preferences[user_id]
        prefs.last_active = time.time()
        prefs.total_interactions += 1
        
        # æ›´æ–°æƒ…æ„Ÿæƒé‡
        if correct_tag not in prefs.emotion_weights:
            prefs.emotion_weights[correct_tag] = 1.0
        
        # å¢åŠ è¯¥æƒ…æ„Ÿçš„æƒé‡
        prefs.emotion_weights[correct_tag] = min(
            prefs.emotion_weights[correct_tag] + 0.05,
            2.0  # æœ€å¤§2.0å€
        )
        
        # è®°å½•å¸¸ç”¨çŸ­è¯­
        if len(text) <= 20:
            prefs.common_phrases[text] = correct_tag
        
        self._save_user_preferences()

    def _load_feedback(self):
        """åŠ è½½åé¦ˆè®°å½•"""
        if not self.feedback_file.exists():
            return
        
        try:
            with open(self.feedback_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.feedback_records = [
                    FeedbackRecord(**record) for record in data
                ]
        except Exception as e:
            print(f"åŠ è½½åé¦ˆè®°å½•å¤±è´¥: {e}")

    def _save_feedback(self):
        """ä¿å­˜åé¦ˆè®°å½•"""
        try:
            data = [
                {
                    "text": r.text,
                    "predicted_tag": r.predicted_tag,
                    "correct_tag": r.correct_tag,
                    "timestamp": r.timestamp,
                    "user_id": r.user_id,
                    "confidence": r.confidence
                }
                for r in self.feedback_records[-500:]  # åªä¿ç•™æœ€è¿‘500æ¡
            ]
            with open(self.feedback_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜åé¦ˆè®°å½•å¤±è´¥: {e}")

    def _load_user_preferences(self):
        """åŠ è½½ç”¨æˆ·åå¥½"""
        if not self.preferences_file.exists():
            return
        
        try:
            with open(self.preferences_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for user_id, prefs_data in data.items():
                    self.user_preferences[user_id] = UserPreferences(
                        user_id=user_id,
                        emotion_weights=prefs_data.get("emotion_weights", {}),
                        common_phrases=prefs_data.get("common_phrases", {}),
                        last_active=prefs_data.get("last_active", 0.0),
                        total_interactions=prefs_data.get("total_interactions", 0)
                    )
        except Exception as e:
            print(f"åŠ è½½ç”¨æˆ·åå¥½å¤±è´¥: {e}")

    def _save_user_preferences(self):
        """ä¿å­˜ç”¨æˆ·åå¥½"""
        try:
            data = {
                user_id: {
                    "emotion_weights": prefs.emotion_weights,
                    "common_phrases": prefs.common_phrases,
                    "last_active": prefs.last_active,
                    "total_interactions": prefs.total_interactions
                }
                for user_id, prefs in self.user_preferences.items()
            }
            with open(self.preferences_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜ç”¨æˆ·åå¥½å¤±è´¥: {e}")

    def _save_emotion_nodes(self):
        """ä¿å­˜æƒ…æ„ŸèŠ‚ç‚¹ï¼ˆå¯é€‰ï¼Œç”¨äºæŒä¹…åŒ–å­¦ä¹ ç»“æœï¼‰"""
        nodes_file = self.data_dir / "emotion_nodes.json"
        try:
            with open(nodes_file, 'w', encoding='utf-8') as f:
                json.dump(self.EMOTION_NODES, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜æƒ…æ„ŸèŠ‚ç‚¹å¤±è´¥: {e}")

    def _calculate_global_boost(self, text: str) -> float:
        boost = 1.0
        
        if "!" in text or "ï¼" in text:
            boost += 0.2
        if "..." in text or "â€¦" in text:
            boost += 0.1
        if self.re_repeat_chars.search(text):
            boost += 0.3
        
        return boost

    def _calculate_question_penalty(self, text: str) -> float:
        if self.re_question.search(text):
            return 0.4
        return 1.0

    def _calculate_text_length_norm(self, text_len: int) -> float:
        if not self.ADVANCED_CONFIG["enable_text_length_norm"]:
            return 1.0
        
        if text_len < 10:
            return 1.0
        elif text_len < 50:
            return 1.0 - (text_len - 10) * self.ADVANCED_CONFIG["text_length_factor"] * 0.01
        else:
            return 0.6

    def _calculate_position_weight(self, pos: int, text_len: int, bonus: float) -> float:
        if not self.ADVANCED_CONFIG["enable_position_weight"]:
            return 1.0
        
        if text_len == 0:
            return 1.0
        
        relative_pos = pos / text_len
        
        if relative_pos < 0.2:
            return bonus * 1.3
        elif relative_pos < 0.5:
            return bonus * 1.1
        elif relative_pos < 0.8:
            return bonus * 1.0
        else:
            return bonus * 0.9

    def _calculate_node_weight(
        self, 
        text: str, 
        start_idx: int, 
        end_idx: int, 
        base_score: float,
        pos_weight: float = 1.0
    ) -> float:
        window_start = max(0, start_idx - self.WINDOW_SIZE)
        window_text = text[window_start:start_idx]
        
        multiplier = 1.0
        
        sorted_modifiers = sorted(
            self.MODIFIERS.items(),
            key=lambda x: x[1]['priority'],
            reverse=True
        )
        
        for mod_type, mod_data in sorted_modifiers:
            for word in mod_data['words']:
                if word in window_text:
                    multiplier *= mod_data['weight']
                    break
        
        if self._is_in_negation_scope(text, start_idx):
            multiplier *= -0.5
        
        return base_score * multiplier * pos_weight

    def _is_in_negation_scope(self, text: str, pos: int) -> bool:
        scope_start = max(0, pos - self.ADVANCED_CONFIG["negation_scope"])
        scope_text = text[scope_start:pos]
        
        return any(neg in scope_text for neg in self.MODIFIERS["negate"]["words"])

    def _calculate_confidence(self, score: float, threshold: float, priority: int) -> float:
        if threshold == 0:
            return 0.0
        
        base_confidence = min((score - threshold) / threshold, 1.0)
        
        if priority == 2:
            base_confidence = min(base_confidence + 0.2, 1.0)
        elif priority == 1:
            base_confidence = min(base_confidence + 0.1, 1.0)
        
        return max(base_confidence, 0.0)

    def _detect_mixed_emotions(self, candidates: List[Tuple[str, float]]) -> List[Tuple[str, float]]:
        if len(candidates) < 2:
            return []
        
        total = sum(v for _, v in candidates)
        
        mixed = []
        for tag, score in candidates:
            ratio = score / total
            if ratio > 0.2:
                mixed.append((tag, ratio))
        
        return sorted(mixed, key=lambda x: x[1], reverse=True)[:3]

    def get_analysis_details(self, text: str, user_id: Optional[str] = None, enable_negation: bool = True) -> AnalysisResult:
        return self._analyze_advanced(text, user_id, enable_negation)

    def get_statistics(self) -> Dict[str, any]:
        return {
            "total_analyzed": self.stats["total_analyzed"],
            "avg_time_ms": self.stats["avg_time"] * 1000,
            "feedback_count": self.stats["feedback_count"],
            "learning_updates": self.stats["learning_updates"],
            "user_count": len(self.user_preferences),
            "cache_hit_rate": (
                self.stats["cache_hits"] / self.stats["total_analyzed"]
                if self.stats["total_analyzed"] > 0 else 0
            )
        }

    def reset_statistics(self):
        self.stats = {
            "total_analyzed": 0,
            "cache_hits": 0,
            "avg_time": 0.0,
            "feedback_count": 0,
            "learning_updates": 0
        }

    def get_user_preferences(self, user_id: str) -> Optional[UserPreferences]:
        """è·å–ç”¨æˆ·åå¥½"""
        return self.user_preferences.get(user_id)

    def get_learning_summary(self) -> Dict[str, any]:
        """è·å–å­¦ä¹ æ€»ç»“"""
        if not self.feedback_records:
            return {"message": "æš‚æ— åé¦ˆæ•°æ®"}
        
        recent_feedback = self.feedback_records[-50:]
        
        accuracy_stats = defaultdict(lambda: {"correct": 0, "total": 0})
        for record in recent_feedback:
            if record.correct_tag:
                accuracy_stats[record.predicted_tag]["total"] += 1
                if record.predicted_tag == record.correct_tag:
                    accuracy_stats[record.predicted_tag]["correct"] += 1
        
        accuracy_by_tag = {}
        for tag, stats in accuracy_stats.items():
            if stats["total"] > 0:
                accuracy_by_tag[tag] = {
                    "accuracy": stats["correct"] / stats["total"],
                    "total": stats["total"]
                }
        
        return {
            "total_feedback": len(self.feedback_records),
            "recent_feedback": len(recent_feedback),
            "accuracy_by_tag": accuracy_by_tag,
            "learning_updates": self.stats["learning_updates"],
            "active_users": len(self.user_preferences)
        }
